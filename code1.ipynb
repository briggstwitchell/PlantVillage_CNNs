{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 18:24:51.291786: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PORTION = 'full'\n",
    "\n",
    "base_dir = f\"{os.getcwd()}/dataset/{DATASET_PORTION}\"\n",
    "train_dir = f\"{base_dir}/train_and_validation/train\"\n",
    "valid_dir = f\"{base_dir}/train_and_validation/validation\"\n",
    "test_dir = f\"{base_dir}/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`flow_from_directory()` expects to read from a series of directories at the specified path, where each directory is a class and each file within that directory is a data instance.\n",
    "\n",
    "Below, for example, I'm reading in the train directory `./dataset/subset/train_and_validation/train` which contains the classes in sub-directories (ex `Apple___Apple_scab`), and within this sub-directory the image files are listed (ex. `Apple___Apple_scab/0a5e9323-dbad-432d-ac58-d291718345d9___FREC_Scab 3417_90deg.JPG`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56248 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3503 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 460800)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                29491264  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 38)                2470      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29586982 (112.87 MB)\n",
      "Trainable params: 29586982 (112.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(256,256,3)),\n",
    "        layers.Conv2D(32, 3, padding='valid', activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        layers.Conv2D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3, activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(38, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(),#from_logits=True\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 - 153s - loss: 1.7821 - accuracy: 0.4900 - val_loss: 1.7029 - val_accuracy: 0.5104 - 153s/epoch - 2s/step\n",
      "Epoch 2/5\n",
      "100/100 - 145s - loss: 1.4807 - accuracy: 0.5694 - val_loss: 1.5047 - val_accuracy: 0.5786 - 145s/epoch - 1s/step\n",
      "Epoch 3/5\n",
      "100/100 - 128s - loss: 1.2483 - accuracy: 0.6269 - val_loss: 1.3721 - val_accuracy: 0.5983 - 128s/epoch - 1s/step\n",
      "Epoch 4/5\n",
      "100/100 - 128s - loss: 1.1291 - accuracy: 0.6684 - val_loss: 1.2630 - val_accuracy: 0.6297 - 128s/epoch - 1s/step\n",
      "Epoch 5/5\n",
      "100/100 - 129s - loss: 1.0070 - accuracy: 0.6999 - val_loss: 1.2189 - val_accuracy: 0.6403 - 129s/epoch - 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f8ae98b3ac0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=validation_generator,\n",
    "    batch_size=32,\n",
    "    epochs=5,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 2.3268 - accuracy: 0.3939 - 489ms/epoch - 244ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3267996311187744, 0.39393940567970276]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "    test_generator,\n",
    "    batch_size=32,\n",
    "    verbose=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
